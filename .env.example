# LLM backend: "ollama" or "groq"
LLM_BACKEND=ollama
# If using Ollama locally:
OLLAMA_URL=http://127.0.0.1:11434
# If using Groq (user must provide their own key):
GROQ_API_KEY=YOUR_GROQ_KEY_HERE
# Vector DB selection: "chroma" or "weaviate"
VECTOR_BACKEND=chroma
# Weaviate (optional local docker-compose)
WEAVIATE_ENDPOINT=http://localhost:8081
WEAVIATE_API_KEY=
